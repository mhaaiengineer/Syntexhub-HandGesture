{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "951607b9-808d-42be-ad51-b0d5cdf36a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d27a12dd-6643-4b18-b595-ddbf73110f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finger_is_up(landmarks, tip_idx, pip_idx):\n",
    "    return landmarks.landmark[tip_idx].y < landmarks.landmark[pip_idx].y\n",
    "\n",
    "def classify_gesture(landmarks):\n",
    "    up_index = finger_is_up(landmarks, 8, 6)\n",
    "    up_middle = finger_is_up(landmarks, 12, 10)\n",
    "    up_ring = finger_is_up(landmarks, 16, 14)\n",
    "    up_pinky = finger_is_up(landmarks, 20, 18)\n",
    "    thumb_up = landmarks.landmark[4].y < landmarks.landmark[3].y\n",
    "\n",
    "    if up_index and up_middle and up_ring and up_pinky and thumb_up:\n",
    "        return \"Open Palm\"\n",
    "    if (not up_index) and (not up_middle) and (not up_ring) and (not up_pinky):\n",
    "        if thumb_up:\n",
    "            return \"Thumbs Up\"\n",
    "        return \"Fist\"\n",
    "    if thumb_up and (not up_index and not up_middle and not up_ring and not up_pinky):\n",
    "        return \"Thumbs Up\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "def gesture_to_action(gesture):\n",
    "    mapping = {\"Open Palm\": \"PAUSE\", \"Fist\": \"PLAY\", \"Thumbs Up\": \"LIKE\"}\n",
    "    return mapping.get(gesture, \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea6ef8c-e199-46ae-b61f-13bdfdf36725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls: 'c' to calibrate (capture hand size), 'd' toggle debug, 's' toggle landmarks, 'q' quit.\n"
     ]
    }
   ],
   "source": [
    "# Debugging & Auto-calibration gesture cell (paste into Jupyter)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='google.protobuf')\n",
    "\n",
    "import cv2, mediapipe as mp, time, math, pyautogui, numpy as np\n",
    "from collections import deque, Counter\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# ---------------- PARAMETERS (tweak these) ----------------\n",
    "MODEL_COMPLEXITY = 1          # 0 = faster, 1 = more accurate\n",
    "MIN_DET_CONF = 0.6\n",
    "MIN_TRACK_CONF = 0.6\n",
    "\n",
    "HISTORY_LEN = 6              # smoothing buffer length\n",
    "ACTION_COOLDOWN = 1.2        # secs\n",
    "FIST_REL_THRESH = 0.60       # lower -> stricter fist detection, raise if misses\n",
    "OK_REL_THRESH = 0.22         # threshold for thumb-index for OK\n",
    "CALIB_FRAMES = 25            # #frames used for calibration\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# helpers\n",
    "def euclid_xy(a, b):\n",
    "    return math.hypot(a.x - b.x, a.y - b.y)\n",
    "\n",
    "def wrist_to_index_distance(landmarks):\n",
    "    return euclid_xy(landmarks.landmark[0], landmarks.landmark[8]) + 1e-9\n",
    "\n",
    "def finger_is_up(landmarks, tip_idx, pip_idx):\n",
    "    return landmarks.landmark[tip_idx].y < landmarks.landmark[pip_idx].y\n",
    "\n",
    "# raw classifier (same logic, using REL sizes)\n",
    "def classify_gesture_raw(landmarks, rel_size):\n",
    "    up_index = finger_is_up(landmarks, 8, 6)\n",
    "    up_middle = finger_is_up(landmarks, 12, 10)\n",
    "    up_ring = finger_is_up(landmarks, 16, 14)\n",
    "    up_pinky = finger_is_up(landmarks, 20, 18)\n",
    "    thumb_up = landmarks.landmark[4].y < landmarks.landmark[3].y\n",
    "    fingers_up = sum([up_index, up_middle, up_ring, up_pinky])\n",
    "\n",
    "    # distances normalized by rel_size\n",
    "    d_index = euclid_xy(landmarks.landmark[8], landmarks.landmark[0]) / rel_size\n",
    "    d_middle = euclid_xy(landmarks.landmark[12], landmarks.landmark[0]) / rel_size\n",
    "    d_ring = euclid_xy(landmarks.landmark[16], landmarks.landmark[0]) / rel_size\n",
    "    d_pinky = euclid_xy(landmarks.landmark[20], landmarks.landmark[0]) / rel_size\n",
    "    d_thumb_index = euclid_xy(landmarks.landmark[4], landmarks.landmark[8]) / rel_size\n",
    "\n",
    "    # 1) Fist\n",
    "    if (d_index < FIST_REL_THRESH) and (d_middle < FIST_REL_THRESH) and (d_ring < FIST_REL_THRESH) and (d_pinky < FIST_REL_THRESH):\n",
    "        return \"Fist\", {\"d_index\":d_index,\"d_middle\":d_middle,\"d_ring\":d_ring,\"d_pinky\":d_pinky}\n",
    "    # 2) Peace\n",
    "    if up_index and up_middle and (not up_ring) and (not up_pinky):\n",
    "        return \"Peace (V)\", {}\n",
    "    # 3) Pointing\n",
    "    if up_index and (not up_middle) and (not up_ring) and (not up_pinky):\n",
    "        return \"Pointing\", {}\n",
    "    # 4) OK\n",
    "    if d_thumb_index < OK_REL_THRESH:\n",
    "        return \"OK\", {\"d_thumb_index\":d_thumb_index}\n",
    "    # 5) Open Palm\n",
    "    if fingers_up == 4 and thumb_up:\n",
    "        return \"Open Palm\", {}\n",
    "    # 6) Thumbs up/down\n",
    "    if (not up_index) and (not up_middle) and (not up_ring) and (not up_pinky):\n",
    "        thumb_tip = landmarks.landmark[4]\n",
    "        wrist = landmarks.landmark[0]\n",
    "        if thumb_tip.y < wrist.y:\n",
    "            return \"Thumbs Up\", {}\n",
    "        else:\n",
    "            return \"Thumbs Down\", {}\n",
    "    return \"Unknown\", {}\n",
    "\n",
    "def gesture_to_action(gesture):\n",
    "    mapping = {\n",
    "        \"Open Palm\": \"PAUSE\",\n",
    "        \"Fist\": \"None\",           # disable Fist action\n",
    "        \"Thumbs Up\": \"VOL_UP\",\n",
    "        \"Thumbs Down\": \"VOL_DOWN\",\n",
    "        \"Peace (V)\": \"PLAY\",      # ✌️ now plays video/music\n",
    "        \"OK\": \"CONFIRM\",\n",
    "        \"Pointing\": \"SELECT\",\n",
    "        \"Unknown\": \"None\"\n",
    "    }\n",
    "    return mapping.get(gesture, \"None\")\n",
    "\n",
    "\n",
    "def perform_action(action):\n",
    "    if action == \"PLAY\" or action == \"PAUSE\":\n",
    "        pyautogui.press(\"space\")\n",
    "    elif action == \"NEXT\":\n",
    "        pyautogui.hotkey(\"ctrl\", \"right\")\n",
    "    elif action == \"VOL_UP\":\n",
    "        pyautogui.press(\"volumeup\")\n",
    "    elif action == \"VOL_DOWN\":\n",
    "        pyautogui.press(\"volumedown\")\n",
    "    elif action == \"CONFIRM\":\n",
    "        pyautogui.press(\"enter\")\n",
    "    elif action == \"SELECT\":\n",
    "        pyautogui.click()\n",
    "\n",
    "# ---------- state ----------\n",
    "show_landmarks = True\n",
    "debug_mode = True   # toggle on-screen numeric debug info\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "gesture_buffers = [deque(maxlen=HISTORY_LEN), deque(maxlen=HISTORY_LEN)]\n",
    "last_action_time = 0\n",
    "\n",
    "# calibration storage\n",
    "calibrating = False\n",
    "calib_counts = 0\n",
    "calib_size_accum = 0.0\n",
    "calibrated_size = None\n",
    "\n",
    "print(\"Controls: 'c' to calibrate (capture hand size), 'd' toggle debug, 's' toggle landmarks, 'q' quit.\")\n",
    "\n",
    "with mp_hands.Hands(max_num_hands=2, model_complexity=MODEL_COMPLEXITY,\n",
    "                    min_detection_confidence=MIN_DET_CONF,\n",
    "                    min_tracking_confidence=MIN_TRACK_CONF) as hands:\n",
    "    prev_time = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Camera error.\")\n",
    "            break\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        h, w, _ = frame.shape\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks and results.multi_handedness:\n",
    "            for idx, (hand_landmarks, hand_handedness) in enumerate(zip(results.multi_hand_landmarks, results.multi_handedness)):\n",
    "                rel_size = wrist_to_index_distance(hand_landmarks)\n",
    "                # if user calibrated, scale by that\n",
    "                rel_scale = calibrated_size if calibrated_size else rel_size\n",
    "\n",
    "                gesture, debug_vals = classify_gesture_raw(hand_landmarks, rel_scale)\n",
    "                if idx < 2:\n",
    "                    gesture_buffers[idx].append(gesture)\n",
    "                # majority vote\n",
    "                most_common, count = Counter(gesture_buffers[idx]).most_common(1)[0] if gesture_buffers[idx] else (\"Unknown\",0)\n",
    "                smoothed = most_common if count >= (HISTORY_LEN//2) else \"Unknown\"\n",
    "                action = gesture_to_action(smoothed)\n",
    "\n",
    "                # draw\n",
    "                xs = [lm.x for lm in hand_landmarks.landmark]\n",
    "                ys = [lm.y for lm in hand_landmarks.landmark]\n",
    "                x_min, x_max = int(min(xs)*w)-10, int(max(xs)*w)+10\n",
    "                y_min, y_max = int(min(ys)*h)-30, int(max(ys)*h)+10\n",
    "                y_min = max(0, y_min)\n",
    "                if show_landmarks:\n",
    "                    mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                label_text = f\"{hand_handedness.classification[0].label} | {smoothed} | {action}\"\n",
    "                cv2.rectangle(frame, (x_min,y_min), (x_max,y_max), (10,150,10), 2)\n",
    "                cv2.putText(frame, label_text, (x_min+5, y_min+20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "                cv2.putText(frame, f\"{int(hand_handedness.classification[0].score*100)}%\", (x_max-50, y_min+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200), 1)\n",
    "\n",
    "                # debug overlays (numeric)\n",
    "                if debug_mode:\n",
    "                    # show rel_size & debug_vals\n",
    "                    cv2.putText(frame, f\"rel_size:{rel_size:.3f}\", (x_min+5, y_max+20), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (220,220,0), 1)\n",
    "                    yline = y_max+40\n",
    "                    for k,v in debug_vals.items():\n",
    "                        cv2.putText(frame, f\"{k}:{v:.3f}\", (x_min+5, yline), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (200,200,200), 1)\n",
    "                        yline += 18\n",
    "\n",
    "                # perform action with cooldown\n",
    "                current_time = time.time()\n",
    "                if action != \"None\" and (current_time - last_action_time > ACTION_COOLDOWN):\n",
    "                    perform_action(action)\n",
    "                    last_action_time = current_time\n",
    "\n",
    "        # show calibration status if running\n",
    "        if calibrating:\n",
    "            cv2.putText(frame, f\"Calibrating... {calib_counts}/{CALIB_FRAMES}\", (10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,200,200),2)\n",
    "        elif calibrated_size:\n",
    "            cv2.putText(frame, f\"Calibrated size: {calibrated_size:.3f}\", (10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (180,180,180),2)\n",
    "\n",
    "        # fps & hints\n",
    "        curr_time = time.time()\n",
    "        fps = 1/(curr_time-prev_time) if prev_time else 0.0\n",
    "        prev_time = curr_time\n",
    "        cv2.putText(frame, f\"FPS:{int(fps)}\", (10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255),2)\n",
    "        cv2.putText(frame, \"q:quit  c:calibrate  d:debug  s:landmarks\", (10, h-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200,200,200),1)\n",
    "\n",
    "        cv2.imshow(\"Gesture Debugger\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        if key == ord('s'):\n",
    "            show_landmarks = not show_landmarks\n",
    "        if key == ord('d'):\n",
    "            debug_mode = not debug_mode\n",
    "        if key == ord('c'):\n",
    "            # start calibration\n",
    "            calibrating = True\n",
    "            calib_counts = 0\n",
    "            calib_size_accum = 0.0\n",
    "            calibrated_size = None\n",
    "\n",
    "        # handle calibration accumulation outside loop to avoid missing frames\n",
    "        if calibrating and results and results.multi_hand_landmarks:\n",
    "            # accumulate relative size from first detected hand\n",
    "            first = results.multi_hand_landmarks[0]\n",
    "            cs = wrist_to_index_distance(first)\n",
    "            calib_size_accum += cs\n",
    "            calib_counts += 1\n",
    "            if calib_counts >= CALIB_FRAMES:\n",
    "                calibrated_size = calib_size_accum / calib_counts\n",
    "                calibrating = False\n",
    "                print(f\"Calibration done. calibrated_size = {calibrated_size:.4f}\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
